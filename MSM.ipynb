{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General stuff\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from subprocess import Popen, PIPE\n",
    "from os.path import join as opj\n",
    "from IPython.core.debugger import Tracer\n",
    "from nilearn.decomposition import CanICA,DictLearning\n",
    "from sklearn.decomposition import DictionaryLearning\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.decomposition import TruncatedSVD,FastICA,SparsePCA,MiniBatchSparsePCA\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.decomposition import dict_learning_online\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import scale\n",
    "import sklearn.metrics.cluster as metrics\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster.hierarchical import _hc_cut # Internal function to cut ward tree, helps speed up things a lot\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# personal functions\n",
    "from importlib import reload\n",
    "import fsutils as fs\n",
    "reload(fs)\n",
    "\n",
    "if os.path.exists('/data1/vbeliveau/'):\n",
    "    # On NRU server\n",
    "    cluster_code='/data1/vbeliveau/5HT_clustering'\n",
    "    cluster_data='/data1/vbeliveau/5HT_clustering_data'\n",
    "    subjects_dir='/usr/local/nru/freesurfer/subjects'\n",
    "elif os.path.exists('C:/Users/vbeliveau/'):\n",
    "    # On laptop\n",
    "    cluster_code='C:/Users/vbeliveau/Documents/GitHub/5HT_clustering'\n",
    "    cluster_data='C:/Users/vbeliveau/Documents/5HT_clustering_data'\n",
    "    subjects_dir='C:/Users/vbeliveau/Downloads/'\n",
    "else:\n",
    "    raise ValueError('Unknown location')\n",
    "    \n",
    "# Load local version of nilearn\n",
    "if os.path.exists('/data1/vbeliveau/'):\n",
    "    sys.path.append('/data1/vbeliveau/nilearn')\n",
    "    import mynilearn.decomposition as dcm \n",
    "    reload(dcm)\n",
    "elif os.path.exists('C:/Users/vbeliveau/'):\n",
    "    sys.path.append('C:/Users/vbeliveau/Downloads/nilearn-master')\n",
    "    import mynilearn.decomposition as dcm\n",
    "    reload(dcm)\n",
    "else:\n",
    "    raise ValueError('Unknown location')\n",
    "    \n",
    "# Analysis directories\n",
    "surf_data=opj(cluster_data,'surf_data')\n",
    "fs.assert_dir(surf_data)\n",
    "BPnd_data=opj(cluster_data,'BPnd')\n",
    "fs.assert_dir(BPnd_data)\n",
    "\n",
    "info_path=opj(cluster_code,'info_alltracers_base_healthy_hrrt.mat')\n",
    "hemi_type=['lh','rh']\n",
    "\n",
    "info=sio.loadmat(info_path)\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "petID=np.array([item for subl in info['petID'] for subsubl in subl for item in subsubl])\n",
    "\n",
    "# define MSMdir\n",
    "msmDir_code = '/data1/vbeliveau/software/MSM_HOCR_v1/Centos/' # new version\n",
    "msmDir_rawdata = '/data1/vbeliveau/5HT_clustering_data/surf_data/bpnd.mrtm2.nopvc.ico'\n",
    "msmDir_analysis = '/data1/Ganz/Vincent'; # change this to a place we both can write?\n",
    "msmDir_data = opj(msmDir_analysis,'surf_data','bpnd.mrtm2.nopvc.ico')\n",
    "fs.assert_dir(msmDir_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "tracers=['cumi'] #,'dasb','sb','az','C36']\n",
    "hemi_type=['lh'] #,'rh']\n",
    "ico='6'\n",
    "smN='3'\n",
    "\n",
    "for tracer,nt in zip(tracers,np.arange(0,len(tracers))):\n",
    "    subjlist=petID[np.array([re.search('^'+tracer,x) is not None for x in petID])]\n",
    "    for hemi in hemi_type:\n",
    "        data=np.ndarray(len(subjlist),dtype=object)\n",
    "        for subj,ns in zip(subjlist,np.arange(0,len(subjlist))):        \n",
    "            fname=opj(msmDir_rawdata,subj + '.ico' + ico + '.' +hemi +'.smN' + smN,'bp.nii.gz')\n",
    "            data[ns] = fs.load_surf_data(fname)        \n",
    "            fname2=opj(msmDir_data,subj + '.ico' + ico + '.' +hemi +'.smN' + smN+'.txt')\n",
    "            np.savetxt(fname2,data[ns],fmt='%.10f')\n",
    "        # Save mean out\n",
    "        fname3=opj(msmDir_data,tracer+'.mean.ico' + ico + '.' +hemi +'.smN' + smN+'.txt')\n",
    "        np.savetxt(fname3,np.vstack(data).mean(axis=0),fmt='%.10f')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run msms command\n",
    "tracers=['cumi'] #,'dasb','sb','az','C36']\n",
    "hemi_type=['lh'] #,'rh']\n",
    "ico='6'\n",
    "smN='3'\n",
    "if ico=='7':\n",
    "    targ='fsaverage'\n",
    "else:\n",
    "    targ='fsaverage'+ico\n",
    "\n",
    "# define config file, see https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/MSM/UserGuide for details\n",
    "configFile = opj(msmDir_analysis,'msm_sulc_depth.config')\n",
    "\n",
    "# Procedure \n",
    "# 1) use sulc aligned functional data on the spherical mesh and align the single subject once given \n",
    "# definition of spherical mesh\n",
    "inmesh_file = opj('/usr/local/nru/freesurfer/subjects',targ,'surf/lh.sphere.shape.gii')\n",
    "\n",
    "for tracer,nt in zip(tracers,np.arange(0,len(tracers))):\n",
    "    subjlist=petID[np.array([re.search('^'+tracer,x) is not None for x in petID])]\n",
    "    for hemi in hemi_type:\n",
    "        for subj in subjlist:\n",
    "            outDir = opj(msmDir_analysis,subj + '.ico' + ico + '.' +hemi +'.smN' + smN+'/') # msm needs dash at end of outputdir\n",
    "            fs.assert_dir(outDir)           \n",
    "            log_file=open(opj(outDir,subj + '.ico' + ico  + '.' +hemi +'.smN' + smN +'.log'),'w')\n",
    "            indata_file = opj(msmDir_data,subj + '.ico' + ico  + '.' +hemi +'.smN' + smN + '.txt')\n",
    "            refdata_file = opj(msmDir_data,tracer + '.mean.ico' + ico + '.' +hemi +'.smN' + smN + '.txt')            \n",
    "\n",
    "            p=Popen([msmDir_code+'/msm','--indata='+indata_file,'--refdata='+refdata_file,'--inmesh='+inmesh_file,\n",
    "                              '--out='+outDir,'--conf='+configFile,'-v'],stdout=log_file, stderr=log_file)\n",
    "            \n",
    "            p.communicate()\n",
    "            log_file.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracers=['cumi'] #,'dasb','sb','az','C36']\n",
    "hemi_type=['lh'] #,'rh']\n",
    "ico='6'\n",
    "smN='3'\n",
    "if ico=='7':\n",
    "    targ='fsaverage'\n",
    "else:\n",
    "    targ='fsaverage'+ico\n",
    "\n",
    "# 2) transform functional data on each subject and redefine an atlas based on the transformed subjects\n",
    "inmesh_file = opj('/usr/local/nru/freesurfer/subjects',targ,'surf/lh.sphere.shape.gii')\n",
    "\n",
    "for tracer,nt in zip(tracers,np.arange(0,len(tracers))):\n",
    "    subjlist=petID[np.array([re.search('^'+tracer,x) is not None for x in petID])]\n",
    "    for hemi in hemi_type:\n",
    "        for subj in subjlist:\n",
    "            outDir = opj(msmDir_analysis,subj + '.ico' + ico + '.' +hemi +'.smN' + smN+'/') # msm needs dash at end of outputdir\n",
    "            fs.assert_dir(outDir) \n",
    "            \n",
    "            p=Popen([msmDir_code+'/msmresample',inmesh_file,outDir,],stdout=log_file, stderr=log_file) # which options to use?\n",
    "            \n",
    "            p.communicate()\n",
    "            log_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracers=['cumi'] #,'dasb','sb','az','C36']\n",
    "hemi_type=['lh'] #,'rh']\n",
    "ico='6'\n",
    "smN='3'\n",
    "if ico=='7':\n",
    "    targ='fsaverage'\n",
    "else:\n",
    "    targ='fsaverage'+ico\n",
    "\n",
    "# 3) evaluate areal distortion and correlation\n",
    "inmesh_file = opj('/usr/local/nru/freesurfer/subjects',targ,'surf/lh.sphere.shape.gii')\n",
    "\n",
    "for tracer,nt in zip(tracers,np.arange(0,len(tracers))):\n",
    "    subjlist=petID[np.array([re.search('^'+tracer,x) is not None for x in petID])]\n",
    "    for hemi in hemi_type:\n",
    "        for subj in subjlist:\n",
    "            outDir = opj(msmDir_analysis,subj + '.ico' + ico + '.' +hemi +'.smN' + smN+'/') # msm needs dash at end of outputdir\n",
    "            fs.assert_dir(outDir) \n",
    "            log_file=open(opj(outDir,subj + '.ico' + ico  + '.' +hemi +'.smN' + smN +'.distortion.log'),'w')\n",
    "            transformedmesh_file = opj(outDir,sphere.reg.surf.gii)\n",
    "            \n",
    "            # areal distortion\n",
    "            p=Popen([msmDir_code+'/estimate_metric_distortion',inmesh_file,transformedmesh_file,outDir,'-abs'],stdout=log_file, stderr=log_file)\n",
    "            \n",
    "            p.communicate()\n",
    "            log_file.close()\n",
    "            \n",
    "            # correlation\n",
    "            # load mean and individual surfaces\n",
    "            # TODO\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
