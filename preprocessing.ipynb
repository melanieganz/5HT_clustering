{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General stuff\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from subprocess import Popen, PIPE\n",
    "from os.path import join as opj\n",
    "from IPython.core.debugger import Tracer\n",
    "from joblib import Parallel, delayed\n",
    "from nilearn.decomposition import CanICA,DictLearning\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.decomposition import TruncatedSVD,FastICA,SparsePCA,MiniBatchSparsePCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import scale\n",
    "import sklearn.metrics.cluster as metrics\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster.hierarchical import _hc_cut # Internal function to cut ward tree, helps speed up things a lot\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# personal functions\n",
    "from importlib import reload\n",
    "import fsutils as fs\n",
    "reload(fs)\n",
    "\n",
    "if os.path.exists('/data1/vbeliveau/'):\n",
    "    # On NRU server\n",
    "    cluster_code='/data1/vbeliveau/5HT_clustering'\n",
    "    cluster_data='/data1/vbeliveau/5HT_clustering_data'\n",
    "    atlas_dir='/data2/5HT_atlas'\n",
    "    importPET=opj(atlas_dir,'import','PET')\n",
    "    procPET=opj(atlas_dir,'proc','PET')\n",
    "    subjects_dir=opj(atlas_dir,'proc','MR','recon_final')\n",
    "elif os.path.exists('C:/Users/vbeliveau/'):\n",
    "    # On laptop\n",
    "    cluster_code='C:/Users/vbeliveau/Documents/GitHub/5HT_clustering'\n",
    "    cluster_data='C:/Users/vbeliveau/Documents/5HT_clustering_data'\n",
    "    subjects_dir='C:/Users/vbeliveau/Downloads/'\n",
    "else:\n",
    "    raise ValueError('Unknown location')\n",
    "    \n",
    "# Load local version of nilearn\n",
    "if os.path.exists('/data1/vbeliveau/'):\n",
    "    sys.path.append('/data1/vbeliveau/nilearn')\n",
    "    import mynilearn.decomposition as dcm \n",
    "    reload(dcm)\n",
    "elif os.path.exists('C:/Users/vbeliveau/'):\n",
    "    sys.path.append('C:/Users/vbeliveau/Downloads/nilearn-master')\n",
    "    import mynilearn.decomposition as dcm\n",
    "    reload(dcm)\n",
    "else:\n",
    "    raise ValueError('Unknown location')\n",
    "    \n",
    "# Analysis directories\n",
    "surf_data=opj(cluster_data,'surf_data')\n",
    "fs.assert_dir(surf_data)\n",
    "BPnd_data=opj(cluster_data,'BPnd')\n",
    "fs.assert_dir(BPnd_data)\n",
    "MFA_data=opj(cluster_data,'MFA')\n",
    "MFA_preproc=opj(MFA_data,'preproc')\n",
    "fs.assert_dir(MFA_data)\n",
    "fs.assert_dir(MFA_preproc)\n",
    "\n",
    "info_path=opj(cluster_code,'info_alltracers_base_healthy_hrrt.mat')\n",
    "hemi_type=['lh','rh']\n",
    "\n",
    "info=sio.loadmat(info_path)\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "petID=np.array([item for subl in info['petID'] for subsubl in subl for item in subsubl])\n",
    "petID=petID[np.array([not re.search('^alt',x) for x in petID])]\n",
    "mrID=np.array([item for subl in info['mrID'] for subsubl in subl for item in subsubl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labels\n",
      "Validating cortex mask, this may take a while\n",
      "Reading 327680 faces and 163842 vertices.\n",
      "10000/149955\n",
      "20000/149955\n",
      "30000/149955\n",
      "40000/149955\n",
      "50000/149955\n",
      "60000/149955\n",
      "70000/149955\n",
      "80000/149955\n",
      "90000/149955\n",
      "Detected invalid vertex 102161\n",
      "Detected invalid vertex 102162\n",
      "100000/149955\n",
      "110000/149955\n",
      "120000/149955\n",
      "130000/149955\n",
      "140000/149955\n",
      "Saving masks to /data1/vbeliveau/5HT_clustering_data/surf_data/mask/fsaverage.lh\n",
      "Reading labels\n",
      "Validating cortex mask, this may take a while\n",
      "Reading 327680 faces and 163842 vertices.\n",
      "10000/149926\n",
      "20000/149926\n",
      "30000/149926\n",
      "40000/149926\n",
      "50000/149926\n",
      "60000/149926\n",
      "70000/149926\n",
      "80000/149926\n",
      "90000/149926\n",
      "100000/149926\n",
      "110000/149926\n",
      "120000/149926\n",
      "130000/149926\n",
      "140000/149926\n",
      "Saving masks to /data1/vbeliveau/5HT_clustering_data/surf_data/mask/fsaverage.rh\n",
      "Reading labels\n",
      "Validating cortex mask, this may take a while\n",
      "Reading 20480 faces and 10242 vertices.\n",
      "Saving masks to /data1/vbeliveau/5HT_clustering_data/surf_data/mask/fsaverage5.lh\n",
      "Reading labels\n",
      "Validating cortex mask, this may take a while\n",
      "Reading 20480 faces and 10242 vertices.\n",
      "Saving masks to /data1/vbeliveau/5HT_clustering_data/surf_data/mask/fsaverage5.rh\n",
      "Reading labels\n",
      "Validating cortex mask, this may take a while\n",
      "Reading 81920 faces and 40962 vertices.\n",
      "10000/37476\n",
      "20000/37476\n",
      "30000/37476\n",
      "Saving masks to /data1/vbeliveau/5HT_clustering_data/surf_data/mask/fsaverage6.lh\n",
      "Reading labels\n",
      "Validating cortex mask, this may take a while\n",
      "Reading 81920 faces and 40962 vertices.\n",
      "10000/37471\n",
      "20000/37471\n",
      "30000/37471\n",
      "Saving masks to /data1/vbeliveau/5HT_clustering_data/surf_data/mask/fsaverage6.rh\n"
     ]
    }
   ],
   "source": [
    "# Create cortex masks\n",
    "\n",
    "hemi_type=['lh','rh']\n",
    "targ_list=['fsaverage5','fsaverage6','fsaverage']\n",
    "dest=opj(surf_data,'mask')\n",
    "fs.assert_dir(dest)\n",
    "\n",
    "for targ in targ_list:\n",
    "    for hemi in hemi_type:\n",
    "        fs.cortex_mask(subjects_dir,targ,hemi,validate=True,verbose=True,\n",
    "                                 save_out=opj(surf_data,'mask',targ+'.'+hemi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create neighbor lists\n",
    "\n",
    "hemi_type=['lh','rh']\n",
    "targ_list=['fsaverage5','fsaverage6']\n",
    "out_list=['matrix','list']\n",
    "dest=opj(surf_data,'neigh')\n",
    "fs.assert_dir(dest)\n",
    "\n",
    "for targ in targ_list:\n",
    "    for hemi in hemi_type:\n",
    "        fmask=opj(surf_data,'mask',targ+'.'+hemi)\n",
    "        for out_type in out_list:\n",
    "            # Whole brain\n",
    "            save_out=opj(surf_data,'neigh',targ+'.'+hemi)\n",
    "            fs.surf_neighborhood(opj(subjects_dir,targ,'surf',hemi+'.pial'),\n",
    "                                    verbose=True, out_type=out_type,save_out=save_out) \n",
    "            \n",
    "            # Cortex only\n",
    "            save_out=opj(surf_data,'neigh',targ+'.'+hemi+'.cortex')\n",
    "            fs.surf_neighborhood(opj(subjects_dir,targ,'surf',hemi+'.pial'),mask=fmask,\n",
    "                                    verbose=True, out_type=out_type,save_out=save_out)            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Resample TACs to sphere\n",
    "\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "hemi_type=['lh','rh']\n",
    "ico_list=['6']\n",
    "pet_file='tac.realigned'\n",
    "fwhm='5'\n",
    "tac_dest=opj(surf_data,'tacs')\n",
    "fs.assert_dir(tac_dest)\n",
    "tac_log_dest=opj(tac_dest,'log')\n",
    "\n",
    "for ico in ico_list:\n",
    "    for hemi in hemi_type:\n",
    "        def mri_vol2surf(subj):\n",
    "            file = open(opj(procPET,subj,'subjectname'),'r')\n",
    "            mrID=file.read()[:-1]\n",
    "            file.close()\n",
    "            tac_file=opj(importPET,subj,pet_file+'.nii.gz');\n",
    "            reg=opj(procPET,subj,pet_file+'.wavg.GD.lta')\n",
    "            out1=opj(tac_dest,subj+'.'+pet_file+'.ico'+ico+'.'+hemi+'.nii.gz')\n",
    "            log_file=open(opj(tac_log_dest,'mri_vol2surf.'+subj+'.ico'+ico+'.'+hemi +'.log'),'w')\n",
    "            p=Popen(['mri_vol2surf','--mov',tac_file,'--projfrac','0.5','--hemi',hemi,\n",
    "                    '--o',out1,'--reg',reg,'--srcsubject',mrID,'--trgsubject','ico',\n",
    "                    '--icoorder',ico],\n",
    "                    stdout=log_file, stderr=log_file)\n",
    "            p.communicate()\n",
    "            log_file.close()\n",
    "        Parallel(n_jobs=20)(delayed (mri_vol2surf)(subj) for subj in petID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Smooth TACs on ico\n",
    "\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "hemi_type=['lh','rh']\n",
    "ico_list=['6']\n",
    "pet_file='tac.realigned'\n",
    "fwhm='5'\n",
    "tac_dest=opj(surf_data,'tacs')\n",
    "log_dest=opj(tac_dest,'log')\n",
    "\n",
    "for ico in ico_list:\n",
    "    if ico==7:\n",
    "        trg = 'fsaverage' \n",
    "    else:\n",
    "        trg = 'fsaverage'+ico\n",
    "    for hemi in hemi_type:\n",
    "        def mris_fwhm(subj):\n",
    "            out1=opj(tac_dest,subj+'.'+pet_file+'.ico'+ico+'.'+hemi+'.nii.gz')        \n",
    "            out2=opj(tac_dest,subj+'.'+pet_file+'.ico'+ico+'.'+hemi+'.sm'+fwhm+'.nii.gz')\n",
    "            log_file=open(opj(log_dest,'mri_surf2surf.'+subj+'.ico'+ico+'.'\n",
    "                              + hemi+'.sm'+fwhm+'.log'),'w')\n",
    "            p=Popen(['mris_fwhm','--i',out1,'--subject',trg,'--hemi',hemi,\n",
    "                    '--cortex','--fwhm',fwhm,'--smooth-only','--o',out2],\n",
    "                    stdout=log_file, stderr=log_file)\n",
    "            p.communicate()\n",
    "            log_file.close()\n",
    "        Parallel(n_jobs=20)(delayed (mris_fwhm)(subj) for subj in petID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform kinetic modeling of TACs on sphere\n",
    "\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "hemi_type=['lh','rh']\n",
    "ico_list=['6']\n",
    "pet_file='tac.realigned'\n",
    "fwhm='5'\n",
    "tac_dest=opj(surf_data,'tacs')\n",
    "dest=opj(surf_data,'bpnd.mrtm2.nopvc')\n",
    "fs.assert_dir(dest)\n",
    "log_dest=opj(dest,'log')\n",
    "fs.assert_dir(log_dest)\n",
    "\n",
    "for ico in ico_list:\n",
    "    if ico==7:\n",
    "        trg = 'fsaverage' \n",
    "    else:\n",
    "        trg = 'fsaverage'+ico\n",
    "    \n",
    "    for hemi in hemi_type:\n",
    "        def mri_glmfit(subj):         \n",
    "            ref_tac=opj(procPET,subj,'nopvc','tac.suit.cereb.dat')\n",
    "            midframe=opj(procPET,subj,'midframe.sec.dat')\n",
    "            file = open(opj(procPET,subj,'nopvc','mrtm-hb','k2prime.dat'),'r')\n",
    "            k2p=file.read()[:-1]\n",
    "            file.close()\n",
    "            tac=opj(tac_dest,subj+'.'+pet_file+'.ico'+ico+'.'+hemi+'.sm'+fwhm+'.nii.gz')   \n",
    "            out=opj(dest,subj+'.ico'+ico+'.'+hemi+'.sm'+fwhm)\n",
    "            log_file=open(opj(log_dest,'mri_glmfit.'+subj+'.ico'+ico+'.'+ hemi +'.log'),'w')\n",
    "            p=Popen(['mri_glmfit','--yhat-save','--y',tac,'--surf',trg,hemi,\n",
    "                     '--o',out,'--nii.gz','--mrtm2',ref_tac,midframe,k2p],\n",
    "                    stdout=log_file, stderr=log_file)\n",
    "            p.communicate()\n",
    "            log_file.close()\n",
    "        Parallel(n_jobs=20)(delayed (mri_glmfit)(subj) for subj in petID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumi\n",
      "dasb\n",
      "sb\n",
      "az\n",
      "C36\n"
     ]
    }
   ],
   "source": [
    "# Convert already existing BPnd maps\n",
    "\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "hemi_type=['lh','rh']\n",
    "targ='fsaverage6'\n",
    "sm='10'\n",
    "    \n",
    "convert=True\n",
    "convert_mean=True\n",
    "\n",
    "maps_dest=opj(BPnd_data,'maps')\n",
    "fs.assert_dir(maps_dest)\n",
    "\n",
    "for tracer in tracers:\n",
    "    \n",
    "    print(tracer)\n",
    "    \n",
    "    surf_dest=maps_dest + '/' + tracer    \n",
    "    fs.assert_dir(surf_dest)\n",
    "    \n",
    "    # If BPnd was not preprocessed (e.g. fsaverage5), do it here\n",
    "    if convert:        \n",
    "        log_dest=opj(surf_dest,'log')\n",
    "        fs.assert_dir(log_dest)\n",
    "        for hemi in hemi_type:\n",
    "            # Convert BPnd from fsaverage to target\n",
    "            sval=opj(atlas_dir,'analyses','bmax_maps','data.nopvc.surf/', \n",
    "                tracer + '.bpnd.mrtm2.nopvc.fsaverage.' + hemi + '.sm' +  sm + '.nii.gz')\n",
    "            tval=opj(surf_dest,'mrtm2.nopvc.' + targ + '.' + hemi + '.sm' + sm + '.nii.gz')\n",
    "\n",
    "            log_file=open(opj(log_dest,'mri_surf2surf.' + hemi +'.log'),'w')\n",
    "            p=Popen(['mri_surf2surf','--srcsubject','fsaverage','--trgsubject',targ,\n",
    "                    '--srchemi',hemi,'--trghemi',hemi,'--sval',sval,'--tval',tval], stdout=log_file, stderr=log_file)\n",
    "            p.communicate()\n",
    "            log_file.close()\n",
    "            \n",
    "    if convert_mean:\n",
    "        log_dest=opj(surf_dest,'log')\n",
    "        fs.assert_dir(log_dest)\n",
    "        for hemi in hemi_type:\n",
    "            # Convert BPnd from fsaverage to target\n",
    "            sval=opj(atlas_dir,'analyses','bmax_maps','data.nopvc.surf', \n",
    "                tracer + '.mean.bpnd.mrtm2.nopvc.fsaverage.' + hemi + '.sm' +  sm + '.nii.gz')\n",
    "            tval=opj(surf_dest,'mean.mrtm2.nopvc.' + targ + '.' + hemi + '.sm' + sm + '.nii.gz')\n",
    "\n",
    "            log_file=open(opj(log_dest,'mri_surf2surf.mean.' + hemi +'.log'),'w')\n",
    "            p=Popen(['mri_surf2surf','--srcsubject','fsaverage','--trgsubject',targ,\n",
    "                    '--srchemi',hemi,'--trghemi',hemi,'--sval',sval,'--tval',tval], stdout=log_file, stderr=log_file)\n",
    "            p.communicate()\n",
    "            log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fsutils' has no attribute 'fs_load_surf_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-107216b7a4f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         fname=opj(BPnd_data,'maps',tracer,'mean.mrtm2.nopvc.' + \n\u001b[1;32m     13\u001b[0m                   targ + '.' + hemi + '.sm' + sm + '.nii.gz')\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs_load_surf_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBPnd_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'maps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mean.scaled.concat.'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mhemi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.sm'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'fsutils' has no attribute 'fs_load_surf_data'"
     ]
    }
   ],
   "source": [
    "# Concatenate mean BPnd maps\n",
    "\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "hemi_type=['lh','rh']\n",
    "targ='fsaverage5'\n",
    "sm='10'\n",
    "\n",
    "for hemi in hemi_type:\n",
    "    img=np.ndarray(len(tracers),dtype=object)\n",
    "    fmask=opj(surf_data,'mask.'+targ+'.'+hemi)\n",
    "    for tracer,nt in zip(tracers,np.arange(0,len(tracers))):\n",
    "        fname=opj(BPnd_data,'maps',tracer,'mean.mrtm2.nopvc.' + \n",
    "                  targ + '.' + hemi + '.sm' + sm + '.nii.gz')\n",
    "        img[nt]=fs.load_surf_data(fname,mask=fmask)\n",
    "        img[nt]=scale(img[nt],axis=0)\n",
    "    fout=opj(BPnd_data,'maps','mean.scaled.concat.'+targ+'.'+hemi+'.sm'+sm+'.nii.gz')\n",
    "    fs.fs_save_surf_data(np.column_stack(img),fout,mask=fmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample TACs to fsaverage surface\n",
    "\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "# tracers=['cumi']\n",
    "hemi_type=['lh','rh']\n",
    "targ='fsaverage5'\n",
    "smooth=['0','5','10']\n",
    "\n",
    "import_pet='/data1/vbeliveau/atlas/import/PET'\n",
    "proc_pet='/data2/FSproc/PET'\n",
    "\n",
    "for tracer in tracers:\n",
    "    \n",
    "    dest=opj(MFA_data,'surf_tacs')\n",
    "    fs.assert_dir(dest)\n",
    "    tracer_dest=opj(dest,tracer)\n",
    "    fs.assert_dir(tracer_dest)\n",
    "    log_dest=opj(tracer_dest,'log')\n",
    "    fs.assert_dir(log_dest)\n",
    "        \n",
    "    subjlist=[item for item in petID if re.search('^'+tracer+'.*',item) is not None]\n",
    "    \n",
    "    for subj in subjlist:\n",
    "        for hemi in hemi_type:\n",
    "            for sm in smooth:\n",
    "\n",
    "                mov=opj(import_pet,subj,'tac.realigned.nii.gz')\n",
    "                reg=opj(proc_pet,subj,'tac.realigned.wavg.GD.lta')\n",
    "                out=opj(tracer_dest,subj + '.' + hemi + '.' + targ + '.sm' + sm + '.nii.gz')\n",
    "                cmd=['mri_vol2surf','--mov',mov,'--reg',reg,'--hemi',hemi,'--o',out,\n",
    "                            '--trgsubject',targ,'--projfrac','0.5','--cortex']\n",
    "                if sm != '0':\n",
    "                    cmd.append('--surf-fwhm')\n",
    "                    cmd.append(sm)\n",
    "\n",
    "                log_file=open(opj(log_dest,'mri_vol2surf.' + subj + '.' + hemi + '.sm' +  sm + '.log'),'w')\n",
    "                p=Popen(cmd, stdout=log_file, stderr=log_file)\n",
    "                p.communicate() # This makes sure we wait for command to be executed before moving on\n",
    "                log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess the raw data for MFA\n",
    "\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "# tracers=['cumi']\n",
    "targ='fsaverage5'\n",
    "smooth=['0','5','10']\n",
    "hemi_type=['lh','rh'] # Note that this order is important when accessing MFA preproc data\n",
    "\n",
    "for tracer in tracers:\n",
    "    hemi_mask={}\n",
    "    subjlist=[item for item in petID if re.search('^'+tracer+'.*',item) is not None]\n",
    "    data_scaled=np.ndarray([len(subjlist)],dtype=object)\n",
    "    for sm in smooth:\n",
    "        for ns in np.arange(0,len(subjlist)):\n",
    "            # Load and concatenate data\n",
    "            data=None\n",
    "            for hemi in hemi_type:\n",
    "                fmask=opj(surf_data,'mask.'+targ+'.'+hemi)\n",
    "                hemi_data=fs.load_surf_data(opj(MFA_data,'surf_tacs',tracer,subjlist[ns] + '.' +\n",
    "                                 hemi + '.' + targ + '.sm' + sm + '.nii.gz'),mask=fmask)\n",
    "                if data is not None:\n",
    "                    data=np.vstack((data,hemi_data))\n",
    "                else:\n",
    "                    data=hemi_data\n",
    "\n",
    "            # Identify empty frames in current hemisphere, and compare to other hemisphere\n",
    "            frames=np.sum(data,axis=0)>10e5 # Here 10e5 is a little random, any better test?            \n",
    "\n",
    "            # Select valid frames, remove column mean and scale by first eigen value\n",
    "            data=data[:,frames]\n",
    "            data=data-data.mean(axis=0)\n",
    "            eig1=np.linalg.svd(data,compute_uv=False)[0]\n",
    "            data_scaled[ns]=data/(eig1/1000)\n",
    "            \n",
    "        # Save out results\n",
    "        np.savez(opj(MFA_preproc,tracer + '.' + targ + '.sm' + sm), data_scaled)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
