{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General stuff\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,re\n",
    "import time\n",
    "import nibabel as nib\n",
    "from subprocess import Popen, PIPE\n",
    "from os.path import join as opj\n",
    "import math\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.decomposition import TruncatedSVD,FastICA,CanICA,DictLearning\n",
    "from sklearn.preprocessing import scale\n",
    "import sklearn.metrics.cluster as metrics\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster.hierarchical import _hc_cut # Internal function to cut ward tree, helps speed up things a lot\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# personal functions\n",
    "from importlib import reload\n",
    "import myutils as mu\n",
    "reload(mu)\n",
    "\n",
    "if os.path.exists('/data1/vbeliveau/'):\n",
    "    # On NRU server\n",
    "    cluster_code='/data1/vbeliveau/5HT_clustering'\n",
    "    cluster_data='/data1/vbeliveau/5HT_clustering_data'\n",
    "    subjects_dir='/usr/local/nru/freesurfer/subjects'\n",
    "elif os.path.exists('C:/Users/vbeliveau/'):\n",
    "    # On laptop\n",
    "    cluster_code='C:/Users/vbeliveau/Documents/GitHub/5HT_clustering'\n",
    "    cluster_data='C:/Users/vbeliveau/Documents/5HT_clustering_data'\n",
    "    subjects_dir='C:/Users/vbeliveau/Downloads/'\n",
    "else:\n",
    "    raise ValueError('Unknown location')\n",
    "    \n",
    "# Analysis directories\n",
    "surf_data=opj(cluster_data,'surf_data')\n",
    "mu.assert_dir(surf_data)\n",
    "BPnd_data=opj(cluster_data,'BPnd')\n",
    "mu.assert_dir(BPnd_data)\n",
    "MFA_data=opj(cluster_data,'MFA')\n",
    "MFA_preproc=opj(MFA_data,'preproc')\n",
    "mu.assert_dir(MFA_data)\n",
    "mu.assert_dir(MFA_preproc)\n",
    "\n",
    "info_path=opj(cluster_code,'info_alltracers_base_healthy_hrrt.mat')\n",
    "hemi_type=['lh','rh']\n",
    "\n",
    "info=sio.loadmat(info_path)\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "petID=[item for subl in info['petID'] for subsubl in subl for item in subsubl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create cortex masks\n",
    "\n",
    "hemi_type=['lh','rh']\n",
    "targ_list=['fsaverage','fsaverage5']\n",
    "\n",
    "for targ in targ_list:\n",
    "    for hemi in hemi_type:\n",
    "        mu.fs_create_cortex_mask(subjects_dir,targ,hemi,validate=True,verbose=True,\n",
    "                                 save_out=opj(surf_data,'mask.'+targ+'.'+hemi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create neighbor lists\n",
    "\n",
    "hemi_type=['lh','rh']\n",
    "targ_list=['fsaverage5']\n",
    "out_list=['matrix','list']\n",
    "\n",
    "for targ in targ_list:\n",
    "    for hemi in hemi_type:\n",
    "        fmask=opj(surf_data,'mask.'+targ+'.'+hemi)\n",
    "        for out_type in out_list:\n",
    "            save_out=opj(surf_data,'neigh.'+targ+'.'+hemi)\n",
    "            mu.fs_surf_neighborhood(opj(subjects_dir,targ,'surf',hemi+'.pial'),mask=fmask,\n",
    "                                    verbose=True, out_type=out_type,save_out=save_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert already existing BPnd maps\n",
    "\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "# tracers=['cumi']\n",
    "# hemi_type=['lh','rh']\n",
    "hemi_type=['lh']\n",
    "targ='fsaverage5'\n",
    "sm='10'\n",
    "    \n",
    "convert=True\n",
    "convert_mean=False\n",
    "\n",
    "maps_dest=opj(BPnd_data,'maps')\n",
    "mu.assert_dir(maps_dest)\n",
    "\n",
    "for tracer in tracers:\n",
    "    \n",
    "    print(tracer)\n",
    "    \n",
    "    surf_dest=maps_dest + '/' + tracer    \n",
    "    mu.assert_dir(surf_dest)\n",
    "    \n",
    "    # If BPnd was not preprocessed (e.g. fsaverage5), do it here\n",
    "    if convert:        \n",
    "        log_dest=opj(surf_dest,'log')\n",
    "        mu.assert_dir(log_dest)\n",
    "        for hemi in hemi_type:\n",
    "            # Convert BPnd from fsaverage to target\n",
    "            sval=opj('/data1/vbeliveau/atlas/analyses/bmax_maps/data.nopvc.surf/' + \n",
    "                tracer + '.bpnd.mrtm2.nopvc.fsaverage.' + hemi + '.sm' +  sm + '.nii.gz')\n",
    "            tval=opj(surf_dest,'mrtm2.nopvc.' + targ + '.' + hemi + '.sm' + sm + '.nii.gz')\n",
    "\n",
    "            log_file=open(opj(log_dest,'mri_surf2surf.' + hemi +'.log'),'w')\n",
    "            p=Popen(['mri_surf2surf','--srcsubject','fsaverage','--trgsubject',targ,\n",
    "                    '--srchemi',hemi,'--trghemi',hemi,'--sval',sval,'--tval',tval], stdout=log_file, stderr=log_file)\n",
    "            p.communicate()\n",
    "            log_file.close()\n",
    "            \n",
    "    if convert_mean:\n",
    "        log_dest=opj(surf_dest,'log')\n",
    "        mu.assert_dir(log_dest)\n",
    "        for hemi in hemi_type:\n",
    "            # Convert BPnd from fsaverage to target\n",
    "            sval=('/data1/vbeliveau/atlas/analyses/bmax_maps/data.nopvc.surf/' + \n",
    "                tracer + '.mean.bpnd.mrtm2.nopvc.fsaverage.' + hemi + '.sm' +  sm + '.nii.gz')\n",
    "            tval=opj(surf_dest,'mean.mrtm2.nopvc.' + targ + '.' + hemi + '.sm' + sm + '.nii.gz')\n",
    "\n",
    "            log_file=open(opj(log_dest,'mri_surf2surf.mean.' + hemi +'.log'),'w')\n",
    "            p=Popen(['mri_surf2surf','--srcsubject','fsaverage','--trgsubject',targ,\n",
    "                    '--srchemi',hemi,'--trghemi',hemi,'--sval',sval,'--tval',tval], stdout=log_file, stderr=log_file)\n",
    "            p.communicate()\n",
    "            log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate mean BPnd maps\n",
    "\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "hemi_type=['lh','rh']\n",
    "targ='fsaverage5'\n",
    "sm='10'\n",
    "\n",
    "for hemi in hemi_type:\n",
    "    img=np.ndarray(len(tracers),dtype=object)\n",
    "    fmask=opj(surf_data,'mask.'+targ+'.'+hemi)\n",
    "    for tracer,nt in zip(tracers,np.arange(0,len(tracers))):\n",
    "        fname=opj(BPnd_data,'maps',tracer,'mean.mrtm2.nopvc.' + \n",
    "                  targ + '.' + hemi + '.sm' + sm + '.nii.gz')\n",
    "        img[nt]=mu.fs_load_surf_data(fname,mask=fmask)\n",
    "        img[nt]=scale(img[nt],axis=0)\n",
    "    fout=opj(BPnd_data,'maps','mean.scaled.concat.'+targ+'.'+hemi+'.sm'+sm+'.nii.gz')\n",
    "    mu.fs_save_surf_data(np.column_stack(img),fout,mask=fmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample TACs to fsaverage surface\n",
    "\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "# tracers=['cumi']\n",
    "hemi_type=['lh','rh']\n",
    "targ='fsaverage5'\n",
    "smooth=['0','5','10']\n",
    "\n",
    "import_pet='/data1/vbeliveau/atlas/import/PET'\n",
    "proc_pet='/data2/FSproc/PET'\n",
    "\n",
    "for tracer in tracers:\n",
    "    \n",
    "    dest=opj(MFA_data,'surf_tacs')\n",
    "    mu.assert_dir(dest)\n",
    "    tracer_dest=opj(dest,tracer)\n",
    "    mu.assert_dir(tracer_dest)\n",
    "    log_dest=opj(tracer_dest,'log')\n",
    "    mu.assert_dir(log_dest)\n",
    "        \n",
    "    subjlist=[item for item in petID if re.search('^'+tracer+'.*',item) is not None]\n",
    "    \n",
    "    for subj in subjlist:\n",
    "        for hemi in hemi_type:\n",
    "            for sm in smooth:\n",
    "\n",
    "                mov=opj(import_pet,subj,'tac.realigned.nii.gz')\n",
    "                reg=opj(proc_pet,subj,'tac.realigned.wavg.GD.lta')\n",
    "                out=opj(tracer_dest,subj + '.' + hemi + '.' + targ + '.sm' + sm + '.nii.gz')\n",
    "                cmd=['mri_vol2surf','--mov',mov,'--reg',reg,'--hemi',hemi,'--o',out,\n",
    "                            '--trgsubject',targ,'--projfrac','0.5','--cortex']\n",
    "                if sm != '0':\n",
    "                    cmd.append('--surf-fwhm')\n",
    "                    cmd.append(sm)\n",
    "\n",
    "                log_file=open(opj(log_dest,'mri_vol2surf.' + subj + '.' + hemi + '.sm' +  sm + '.log'),'w')\n",
    "                p=Popen(cmd, stdout=log_file, stderr=log_file)\n",
    "                p.communicate() # This makes sure we wait for command to be executed before moving on\n",
    "                log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess the raw data for MFA\n",
    "\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "# tracers=['cumi']\n",
    "targ='fsaverage5'\n",
    "smooth=['0','5','10']\n",
    "hemi_type=['lh','rh'] # Note that this order is important when accessing MFA preproc data\n",
    "\n",
    "for tracer in tracers:\n",
    "    hemi_mask={}\n",
    "    subjlist=[item for item in petID if re.search('^'+tracer+'.*',item) is not None]\n",
    "    data_scaled=np.ndarray([len(subjlist)],dtype=object)\n",
    "    eig1=np.empty(len(subjlist))\n",
    "    for sm in smooth:\n",
    "        for ns in np.arange(0,len(subjlist)):\n",
    "            # Load and concatenate data\n",
    "            data=None\n",
    "            for hemi in hemi_type:\n",
    "                fmask=opj(surf_data,'mask.'+targ+'.'+hemi)\n",
    "                hemi_data=mu.fs_load_surf_data(opj(MFA_data,'surf_tacs',tracer,subjlist[ns] + '.' +\n",
    "                                 hemi + '.' + targ + '.sm' + sm + '.nii.gz'),mask=fmask)\n",
    "                if data is not None:\n",
    "                    data=np.vstack((data,hemi_data))\n",
    "                else:\n",
    "                    data=hemi_data\n",
    "\n",
    "            # Identify empty frames in current hemisphere, and compare to other hemisphere\n",
    "            frames=np.sum(data,axis=0)>10e5 # Here 10e5 is a little random, any better test?            \n",
    "\n",
    "            # Select valid frames, Scale data (mean=0 and var=1, row-wise) and compute first eigenval\n",
    "            data_scaled[ns]=scale(data[:,frames],axis=1)\n",
    "            eig1[ns]=np.linalg.svd(data_scaled[ns],compute_uv=False)[0]\n",
    "\n",
    "        # Save out results\n",
    "        np.savez(opj(MFA_preproc,tracer + '.' + targ + '.sm' + sm), data_scaled, eig1)\n",
    "\n",
    "# The following warning was issued when running for the first time, but didn't appear when rerunning.\n",
    "# Will need to investigate further...\n",
    "# /data1/vbeliveau/software/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:160: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
    "#   warnings.warn(\"Numerical issues were encountered \"\n",
    "# /data1/vbeliveau/software/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:177: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
    "#   warnings.warn(\"Numerical issues were encountered \""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
