{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General stuff\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from subprocess import Popen, PIPE\n",
    "from os.path import join as opj\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.preprocessing import scale\n",
    "import sklearn.metrics.cluster as metrics\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# personal functions\n",
    "from importlib import reload\n",
    "import fsutils as fs\n",
    "reload(fs)\n",
    "\n",
    "if os.path.exists('/data1/vbeliveau/'):\n",
    "    # On NRU server\n",
    "    cluster_code='/data1/vbeliveau/5HT_clustering'\n",
    "    cluster_data='/data1/vbeliveau/5HT_clustering_data'\n",
    "    subjects_dir='/usr/local/nru/freesurfer/subjects'\n",
    "elif os.path.exists('C:/Users/vbeliveau/'):\n",
    "    # On laptop\n",
    "    cluster_code='C:/Users/vbeliveau/Documents/GitHub/5HT_clustering'\n",
    "    cluster_data='C:/Users/vbeliveau/Documents/5HT_clustering_data'\n",
    "    subjects_dir='C:/Users/vbeliveau/Downloads/'\n",
    "else:\n",
    "    raise ValueError('Unknown location')\n",
    "    \n",
    "# Load local version of nilearn\n",
    "if os.path.exists('/data1/vbeliveau/'):\n",
    "    sys.path.append('/data1/vbeliveau/nilearn')\n",
    "    import mynilearn.decomposition as dcm \n",
    "    reload(dcm)\n",
    "elif os.path.exists('C:/Users/vbeliveau/'):\n",
    "    sys.path.append('C:/Users/vbeliveau/Downloads/nilearn-master')\n",
    "    import mynilearn.decomposition as dcm\n",
    "    reload(dcm)\n",
    "else:\n",
    "    raise ValueError('Unknown location')\n",
    "    \n",
    "# Analysis directories\n",
    "surf_data=opj(cluster_data,'surf_data')\n",
    "fs.assert_dir(surf_data)\n",
    "BPnd_data=opj(cluster_data,'BPnd')\n",
    "fs.assert_dir(BPnd_data)\n",
    "MFA_data=opj(cluster_data,'MFA')\n",
    "MFA_preproc=opj(MFA_data,'preproc')\n",
    "fs.assert_dir(MFA_data)\n",
    "fs.assert_dir(MFA_preproc)\n",
    "\n",
    "info_path=opj(cluster_code,'info_alltracers_base_healthy_hrrt.mat')\n",
    "hemi_type=['lh','rh']\n",
    "\n",
    "info=sio.loadmat(info_path)\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "petID=[item for subl in info['petID'] for subsubl in subl for item in subsubl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run levelset on mean BPnd maps\n",
    "\n",
    "tracers=['cumi','dasb','sb','az','C36']\n",
    "hemi_type=['lh']\n",
    "targ='fsaverage5'\n",
    "sm='10'\n",
    "\n",
    "data=np.empty(len(tracers),dtype=object)\n",
    "for tracer,nt in zip(tracers,np.arange(0,len(tracers))):\n",
    "    for hemi in hemi_type:\n",
    "        # Load data\n",
    "        fmask=opj(surf_data,'mask.'+targ+'.'+hemi)\n",
    "        fname=opj(BPnd_data,'maps',tracer,'mrtm2.nopvc.' + \n",
    "                  targ + '.' + hemi + '.sm' + sm + '.nii.gz')        \n",
    "        data=np.mean(fs.load_surf_data(fname,mask=fmask),axis=1)\n",
    "        \n",
    "        # Load neighborhood structure\n",
    "        fneigh=opj(surf_data,'neigh.cortex.'+targ+'.'+hemi+'.list')\n",
    "        neigh,_=fs.load_surf_neighborhood(fneigh)\n",
    "        \n",
    "        # Perform levelset clustering\n",
    "        clust=fs.surf_levelset(data,neigh)        \n",
    "        dest=opj(cluster_data,'levelset','test')\n",
    "        fs.assert_dir(dest)\n",
    "        fname=opj(dest,tracer+'.'+targ +'.' +hemi+'.sm' + sm + '.nii.gz') \n",
    "        fs.save_surf_data(clust,fname,mask=fmask)\n",
    "        \n",
    "        # Perform levelset two-sided clustering\n",
    "        clust=fs.surf_levelset_two_sided(data,neigh)\n",
    "        dest=opj(cluster_data,'levelset','test.two-sided')\n",
    "        fs.assert_dir(dest)\n",
    "        fname=opj(dest,tracer+'.'+targ +'.' +hemi+'.sm' + sm + '.nii.gz') \n",
    "        fs.save_surf_data(clust.T,fname,mask=fmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=fs.load_surf_data(fname,mask=fmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9354,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "e62083c0-5297-406b-ac91-6339d2c1cda5",
    "theme": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
